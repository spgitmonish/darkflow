{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from darkflow.net.build import TFNet\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from boxespredict.yolomodeltest import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the .pb file and the .meta file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from .pb and .meta\n",
      "Running entirely on CPU\n"
     ]
    }
   ],
   "source": [
    "# The protocol buffer file and the .meta file\n",
    "# NOTE: The .met file is a JSON dump of everything necessary for post-processing such as anchors \n",
    "#       and labels\n",
    "if os.name == 'nt':\n",
    "    # 30000 steps\n",
    "    #options = {\"pbLoad\": os.getcwd() + \"\\\\saved_graph\\\\30000-tiny-yolo-voc-3c.pb\", \"metaLoad\": os.getcwd() + \"\\\\saved_graph\\\\30000-tiny-yolo-voc-3c.meta\", \"threshold\": 0.1}\n",
    "    \n",
    "    # 40375 steps\n",
    "    options = {\"pbLoad\": os.getcwd() + \"\\\\saved_graph\\\\40375-tiny-yolo-voc-3c.pb\", \"metaLoad\": os.getcwd() + \"\\\\saved_graph\\\\40375-tiny-yolo-voc-3c.meta\", \"threshold\": 0.1}\n",
    "else:\n",
    "    # 30000 steps\n",
    "    #options = {\"pbLoad\": os.getcwd() + \"/saved_graph/30000-tiny-yolo-voc-3c.pb\", \"metaLoad\": os.getcwd() + \"/saved_graph/30000-tiny-yolo-voc-3c.meta\", \"threshold\": 0.1, \"gpu\": 1.0}\n",
    "\n",
    "    #40375 steps\n",
    "    options = {\"pbLoad\": os.getcwd() + \"/saved_graph/40375-tiny-yolo-voc-3c.pb\", \"metaLoad\": os.getcwd() + \"/saved_graph/40375-tiny-yolo-voc-3c.meta\", \"threshold\": 0.1, \"gpu\": 1.0}\n",
    "\n",
    "# Object of Darkflow\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the predictions from the model for all the images in the sample folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from .pb and .meta\n",
      "Cythonized Inference Time 0.472 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\443615\\Documents\\SDC\\Term3\\SystemIntegration\\darkflow\\tf_light_darkflow_test\\boxespredict\\boxes.py:26: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  net_out = net_out_in.reshape([H, W, B, net_out_in.shape[2]/B])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pythonized Inference Time 1.436 seconds\n",
      "Cythonized Inference Time 0.481 seconds\n",
      "Pythonized Inference Time 1.308 seconds\n",
      "Cythonized Inference Time 0.435 seconds\n",
      "Pythonized Inference Time 1.247 seconds\n",
      "Cythonized Inference Time 0.447 seconds\n",
      "Pythonized Inference Time 1.296 seconds\n",
      "Cythonized Inference Time 0.472 seconds\n",
      "Pythonized Inference Time 1.398 seconds\n",
      "Cythonized Inference Time 0.462 seconds\n",
      "Pythonized Inference Time 1.266 seconds\n",
      "Cythonized Inference Time 0.438 seconds\n",
      "Pythonized Inference Time 1.396 seconds\n",
      "Cythonized Inference Time 0.470 seconds\n",
      "Pythonized Inference Time 1.318 seconds\n",
      "Cythonized Inference Time 0.452 seconds\n",
      "Pythonized Inference Time 1.286 seconds\n",
      "Cythonized Inference Time 0.451 seconds\n",
      "Pythonized Inference Time 1.342 seconds\n",
      "Cythonized Inference Time 0.444 seconds\n",
      "Pythonized Inference Time 1.361 seconds\n",
      "Cythonized Inference Time 0.496 seconds\n",
      "Pythonized Inference Time 1.465 seconds\n",
      "Cythonized Inference Time 0.459 seconds\n",
      "Pythonized Inference Time 1.287 seconds\n",
      "Cythonized Inference Time 0.434 seconds\n",
      "Pythonized Inference Time 1.267 seconds\n",
      "Cythonized Inference Time 0.457 seconds\n",
      "Pythonized Inference Time 1.428 seconds\n",
      "Cythonized Inference Time 0.509 seconds\n",
      "Pythonized Inference Time 1.538 seconds\n"
     ]
    }
   ],
   "source": [
    "# Predictions using darkflow cythonized code and non-cythonized code\n",
    "predictions_darkflow = {}\n",
    "predictions_nondarkflow = {}\n",
    "yolo_test = YOLOTest(options)\n",
    "\n",
    "'''NOTE: The Pythonized prediction time is ~1.2 - 1.5s where as the cythonized version is < 0.5s'''\n",
    "for img_file in os.listdir(os.getcwd() + \"/sample_img\"):\n",
    "    file_path = os.getcwd() + \"/sample_img/\" + img_file\n",
    "    imgcv = cv2.imread(file_path)\n",
    "    #t = time.time()\n",
    "    result = tfnet.return_predict(imgcv)\n",
    "    #print(\"Cythonized Inference Time %.3f seconds\" % (time.time() - t))\n",
    "    predictions_darkflow[img_file] = result\n",
    "    #t = time.time()\n",
    "    result = return_predict(imgcv, yolo_test)\n",
    "    #print(\"Pythonized Inference Time %.3f seconds\" % (time.time() - t))\n",
    "    predictions_nondarkflow[img_file] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting previous annotations directory\n"
     ]
    }
   ],
   "source": [
    "# Specify the image size to display(in inches)\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "# Function to visualize predictions on an image and store\n",
    "def visualizePredictions(predictions, source=\"darkflow\"):\n",
    "    # For each of the annnotations result plot the annotation box and display the image\n",
    "    for img_file, results in predictions.items():\n",
    "        # Read the image file\n",
    "        image_file_path = os.getcwd() + \"/sample_img/\" + img_file\n",
    "        image = cv2.imread(image_file_path)\n",
    "\n",
    "        for result in results:\n",
    "            # Get the top left co-ordinates and insert into a tuple\n",
    "            x = result['topleft']['x']\n",
    "            y = result['topleft']['y']\n",
    "            top_left = (x, y)\n",
    "\n",
    "            # Get the top left co-ordinates and insert into a tuple\n",
    "            x = result['bottomright']['x']\n",
    "            y = result['bottomright']['y']\n",
    "            bottom_right = (x, y)\n",
    "\n",
    "            # Get the label and the confidence scores\n",
    "            label = result['label']\n",
    "            confidence = result['confidence']\n",
    "\n",
    "            # Add the bounding boxes and the label with confidence scores if it is above 75%\n",
    "            if confidence > 0.75:\n",
    "                if label == \"red_rect\":\n",
    "                    label_to_display = \"Red\"\n",
    "                    color_to_display = (0, 0, 255)\n",
    "                elif label == \"orange_rect\":\n",
    "                    label_to_display = \"Yellow\"\n",
    "                    color_to_display = (0, 255, 255)\n",
    "                elif label == \"green_rect\":\n",
    "                    label_to_display = \"Green\"\n",
    "                    color_to_display = (0, 255, 0)\n",
    "\n",
    "                # Add the rectangle \n",
    "                image = cv2.rectangle(image, top_left, bottom_right, color_to_display, 3)\n",
    "\n",
    "                # Bottom left of text\n",
    "                bottom_left = (int(image.shape[0]/2) + 20, 20)\n",
    "\n",
    "                # Add the label\n",
    "                image = cv2.putText(image, label_to_display, bottom_left, \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 1, color_to_display, 1)\n",
    "\n",
    "        # Write the final file with or without annotations\n",
    "        cv2.imwrite(annotations_dir + \"/\" + source + \"_\" + img_file, image)\n",
    "        \n",
    "# Remove existing annotations and create new ones based on the results\n",
    "annotations_dir = os.getcwd() + \"/sample_img_annotated\"\n",
    "if os.path.exists(annotations_dir):\n",
    "    print(\"Deleting previous annotations directory\")\n",
    "    shutil.rmtree(annotations_dir)\n",
    "os.makedirs(annotations_dir)\n",
    "\n",
    "# Visualize predictions from the cythonized version and the non-cythonized version\n",
    "visualizePredictions(predictions_darkflow, \"darkflow\")\n",
    "visualizePredictions(predictions_nondarkflow, \"nodarkflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
