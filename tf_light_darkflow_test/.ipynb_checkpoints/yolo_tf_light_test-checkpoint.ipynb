{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from darkflow.net.build import TFNet\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the .pb file and the .meta file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from .pb and .meta\n",
      "GPU mode with 1.0 usage\n"
     ]
    }
   ],
   "source": [
    "# The protocol buffer file and the .meta file\n",
    "# NOTE: The .met file is a JSON dump of everything necessary for post-processing such as anchors \n",
    "#       and labels\n",
    "# 30000 steps\n",
    "#options = {\"pbLoad\": os.getcwd() + \"/saved_graph/30000-tiny-yolo-voc-3c.pb\", \"metaLoad\": os.getcwd() + \"/saved_graph/30000-tiny-yolo-voc-3c.meta\", \"threshold\": 0.1, \"gpu\": 1.0}\n",
    "\n",
    "#40375 steps\n",
    "options = {\"pbLoad\": os.getcwd() + \"/saved_graph/40375-tiny-yolo-voc-3c.pb\", \"metaLoad\": os.getcwd() + \"/saved_graph/40375-tiny-yolo-voc-3c.meta\", \"threshold\": 0.1, \"gpu\": 1.0}\n",
    "\n",
    "# Object of Darkflow\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the predictions from the model for all the images in the sample folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for img_file in os.listdir(os.getcwd() + \"/sample_img\"):\n",
    "    file_path = os.getcwd() + \"/sample_img/\" + img_file\n",
    "    imgcv = cv2.imread(file_path)\n",
    "    result = tfnet.return_predict(imgcv)\n",
    "    predictions[img_file] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'green1.jpg': [{'bottomright': {'x': 462, 'y': 206},\n",
      "                 'confidence': 0.98381954,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 356, 'y': 24}}],\n",
      " 'green2.jpg': [{'bottomright': {'x': 171, 'y': 398},\n",
      "                 'confidence': 0.96925348,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 107, 'y': 237}},\n",
      "                {'bottomright': {'x': 454, 'y': 390},\n",
      "                 'confidence': 0.83314031,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 392, 'y': 250}},\n",
      "                {'bottomright': {'x': 731, 'y': 402},\n",
      "                 'confidence': 0.91575915,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 662, 'y': 253}}],\n",
      " 'green3.jpg': [{'bottomright': {'x': 239, 'y': 460},\n",
      "                 'confidence': 0.91945493,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 190, 'y': 362}},\n",
      "                {'bottomright': {'x': 438, 'y': 458},\n",
      "                 'confidence': 0.83778477,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 395, 'y': 363}},\n",
      "                {'bottomright': {'x': 647, 'y': 464},\n",
      "                 'confidence': 0.89663118,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 599, 'y': 371}}],\n",
      " 'green4.jpg': [{'bottomright': {'x': 260, 'y': 466},\n",
      "                 'confidence': 0.97737819,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 213, 'y': 377}},\n",
      "                {'bottomright': {'x': 447, 'y': 467},\n",
      "                 'confidence': 0.94491887,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 402, 'y': 374}},\n",
      "                {'bottomright': {'x': 640, 'y': 460},\n",
      "                 'confidence': 0.99703157,\n",
      "                 'label': 'green_rect',\n",
      "                 'topleft': {'x': 594, 'y': 376}}],\n",
      " 'nolight1.jpg': [],\n",
      " 'nolight2.jpg': [],\n",
      " 'nolight3.jpg': [],\n",
      " 'nolight4.jpg': [],\n",
      " 'orange1.jpg': [{'bottomright': {'x': 799, 'y': 260},\n",
      "                  'confidence': 0.15641548,\n",
      "                  'label': 'red_rect',\n",
      "                  'topleft': {'x': 718, 'y': 18}},\n",
      "                 {'bottomright': {'x': 370, 'y': 214},\n",
      "                  'confidence': 0.98299873,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 229, 'y': 13}},\n",
      "                 {'bottomright': {'x': 799, 'y': 200},\n",
      "                  'confidence': 0.61149377,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 723, 'y': 40}},\n",
      "                 {'bottomright': {'x': 799, 'y': 319},\n",
      "                  'confidence': 0.28940612,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 653, 'y': 0}}],\n",
      " 'orange2.jpg': [{'bottomright': {'x': 179, 'y': 400},\n",
      "                  'confidence': 0.99741668,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 114, 'y': 267}},\n",
      "                 {'bottomright': {'x': 441, 'y': 413},\n",
      "                  'confidence': 0.99369407,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 380, 'y': 277}},\n",
      "                 {'bottomright': {'x': 700, 'y': 419},\n",
      "                  'confidence': 0.99051905,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 639, 'y': 289}}],\n",
      " 'orange3.jpg': [{'bottomright': {'x': 402, 'y': 550},\n",
      "                  'confidence': 0.98607826,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 374, 'y': 492}},\n",
      "                 {'bottomright': {'x': 383, 'y': 537},\n",
      "                  'confidence': 0.10449755,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 373, 'y': 504}},\n",
      "                 {'bottomright': {'x': 504, 'y': 546},\n",
      "                  'confidence': 0.93643045,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 476, 'y': 491}},\n",
      "                 {'bottomright': {'x': 607, 'y': 545},\n",
      "                  'confidence': 0.99542814,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 584, 'y': 492}}],\n",
      " 'orange4.jpg': [{'bottomright': {'x': 338, 'y': 252},\n",
      "                  'confidence': 0.7955395,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 257, 'y': 98}},\n",
      "                 {'bottomright': {'x': 719, 'y': 267},\n",
      "                  'confidence': 0.87516201,\n",
      "                  'label': 'orange_rect',\n",
      "                  'topleft': {'x': 654, 'y': 122}}],\n",
      " 'red1.jpg': [{'bottomright': {'x': 77, 'y': 288},\n",
      "               'confidence': 0.98062044,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 0, 'y': 35}},\n",
      "              {'bottomright': {'x': 477, 'y': 284},\n",
      "               'confidence': 0.99785447,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 361, 'y': 53}},\n",
      "              {'bottomright': {'x': 799, 'y': 279},\n",
      "               'confidence': 0.30410168,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 766, 'y': 60}}],\n",
      " 'red2.jpg': [{'bottomright': {'x': 148, 'y': 341},\n",
      "               'confidence': 0.96352929,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 67, 'y': 165}},\n",
      "              {'bottomright': {'x': 461, 'y': 339},\n",
      "               'confidence': 0.98513061,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 382, 'y': 172}},\n",
      "              {'bottomright': {'x': 782, 'y': 355},\n",
      "               'confidence': 0.83672625,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 702, 'y': 181}}],\n",
      " 'red3.jpg': [{'bottomright': {'x': 491, 'y': 507},\n",
      "               'confidence': 0.89677197,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 456, 'y': 430}},\n",
      "              {'bottomright': {'x': 641, 'y': 512},\n",
      "               'confidence': 0.99023551,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 608, 'y': 428}},\n",
      "              {'bottomright': {'x': 791, 'y': 505},\n",
      "               'confidence': 0.91504627,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 766, 'y': 437}},\n",
      "              {'bottomright': {'x': 799, 'y': 517},\n",
      "               'confidence': 0.1649881,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 752, 'y': 421}}],\n",
      " 'red4.jpg': [{'bottomright': {'x': 87, 'y': 389},\n",
      "               'confidence': 0.86122227,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 14, 'y': 232}},\n",
      "              {'bottomright': {'x': 366, 'y': 390},\n",
      "               'confidence': 0.89562929,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 303, 'y': 251}},\n",
      "              {'bottomright': {'x': 635, 'y': 413},\n",
      "               'confidence': 0.99173975,\n",
      "               'label': 'red_rect',\n",
      "               'topleft': {'x': 561, 'y': 246}}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting previous annotations directory\n"
     ]
    }
   ],
   "source": [
    "# This is needed to display the images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Remove existing annotations and create new ones based on the results\n",
    "annotations_dir = os.getcwd() + \"/sample_img_annotated\"\n",
    "if os.path.exists(annotations_dir):\n",
    "    print(\"Deleting previous annotations directory\")\n",
    "    shutil.rmtree(annotations_dir)\n",
    "os.makedirs(annotations_dir)\n",
    "\n",
    "# Specify the image size to display(in inches)\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "# For each of the annnotations result plot the annotation box and display the image\n",
    "for img_file, results in predictions.items():\n",
    "    # Read the image file\n",
    "    image_file_path = os.getcwd() + \"/sample_img/\" + img_file\n",
    "    image = cv2.imread(image_file_path)\n",
    "\n",
    "    for result in results:\n",
    "        # Get the top left co-ordinates and insert into a tuple\n",
    "        x = result['topleft']['x']\n",
    "        y = result['topleft']['y']\n",
    "        top_left = (x, y)\n",
    "\n",
    "        # Get the top left co-ordinates and insert into a tuple\n",
    "        x = result['bottomright']['x']\n",
    "        y = result['bottomright']['y']\n",
    "        bottom_right = (x, y)\n",
    "\n",
    "        # Get the label and the confidence scores\n",
    "        label = result['label']\n",
    "        confidence = result['confidence']\n",
    "\n",
    "        # Add the bounding boxes and the label with confidence scores if it is above 75%\n",
    "        if confidence > 0.75:\n",
    "            if label == \"red_rect\":\n",
    "                label_to_display = \"Red\"\n",
    "                color_to_display = (0, 0, 255)\n",
    "            elif label == \"orange_rect\":\n",
    "                label_to_display = \"Yellow\"\n",
    "                color_to_display = (0, 255, 255)\n",
    "            elif label == \"green_rect\":\n",
    "                label_to_display = \"Green\"\n",
    "                color_to_display = (0, 255, 0)\n",
    "                \n",
    "            # Add the rectangle \n",
    "            image = cv2.rectangle(image, top_left, bottom_right, color_to_display, 3)\n",
    "            \n",
    "            # Bottom left of text\n",
    "            bottom_left = (int(image.shape[0]/2) + 20, 20)\n",
    "\n",
    "            # Add the label\n",
    "            image = cv2.putText(image, label_to_display, bottom_left, \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, color_to_display, 1)\n",
    "            \n",
    "    # Write the final file with or without annotations\n",
    "    cv2.imwrite(annotations_dir + \"/\" + img_file, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
